{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 512) (70000,)\n"
     ]
    }
   ],
   "source": [
    "# load resnet extracted features\n",
    "# resnet_data = np.load('./data/extracted_features/resnet-features.npz')\n",
    "# resnet_features = resnet_data['features']\n",
    "# resnet_labels = resnet_data['labels']\n",
    "# print(resnet_features.shape, resnet_labels.shape)\n",
    "resnet_train = np.load('./data/extracted_features/resnet_train.npz')\n",
    "resnet_test = np.load('./data/extracted_features/resnet_test.npz')\n",
    "resnet_train_features = resnet_train['arr_0']\n",
    "resnet_train_labels = resnet_train['arr_1']\n",
    "resnet_test_features = resnet_test['arr_0']\n",
    "resnet_test_labels = resnet_test['arr_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load scattering nets extracted features\n",
    "scatter_train = np.load('./data/extracted_features/scatter_train.npz')\n",
    "scatter_test = np.load('./data/extracted_features/scatter_test.npz')\n",
    "scatter_train_features = scatter_train['arr_0']\n",
    "scatter_train_labels = scatter_train['arr_1']\n",
    "scatter_test_features = scatter_test['arr_0']\n",
    "scatter_test_labels = scatter_test['arr_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 3969) (60000,) (10000, 3969) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(scatter_train_features.shape, scatter_train_labels.shape, scatter_test_features.shape, scatter_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models, datasets, transforms\n",
    "from ipywidgets import IntProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load raw features\n",
    "transform=transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# # MNIST dataset\n",
    "# train_dataset = datasets.MNIST('./data/MNIST', train=True, download=True,\n",
    "#                                transform=transform)\n",
    "# test_dataset = datasets.MNIST('./data/MNIST', train=False,\n",
    "#                                transform=transform)\n",
    "\n",
    "# Fashion MNIST dataset\n",
    "train_dataset = datasets.FashionMNIST('./data/MNIST_fashion', train=True, download=True,\n",
    "                               transform=transform)\n",
    "test_dataset = datasets.FashionMNIST('./data/MNIST_fashion', train=False,\n",
    "                               transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\goodh\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:45: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "raw_train_features = train_dataset.data.reshape(-1,784)\n",
    "raw_train_labels = train_dataset.train_labels\n",
    "raw_test_features = test_dataset.data.reshape(-1,784)\n",
    "raw_test_labels = test_dataset.train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 784])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 512)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_features[:60000,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\goodh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Logistic Regression - raw features]\n",
      "\taccuracy score: 0.8412\n",
      "\tClassification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1000\n",
      "           1       0.96      0.97      0.96       994\n",
      "           2       0.74      0.73      0.73      1011\n",
      "           3       0.86      0.84      0.85      1027\n",
      "           4       0.78      0.71      0.74      1092\n",
      "           5       0.89      0.94      0.92       946\n",
      "           6       0.55      0.64      0.59       858\n",
      "           7       0.93      0.90      0.92      1033\n",
      "           8       0.95      0.93      0.94      1020\n",
      "           9       0.94      0.93      0.94      1019\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.84      0.84      0.84     10000\n",
      "weighted avg       0.85      0.84      0.84     10000\n",
      "\n",
      "\n",
      "[Support Vector Machine - raw features]\n",
      "\taccuracy score: 0.8828\n",
      "\tClassification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.84      1038\n",
      "           1       0.96      0.99      0.98       970\n",
      "           2       0.82      0.79      0.80      1037\n",
      "           3       0.89      0.87      0.88      1024\n",
      "           4       0.81      0.81      0.81      1012\n",
      "           5       0.95      0.96      0.96       987\n",
      "           6       0.65      0.72      0.69       906\n",
      "           7       0.95      0.93      0.94      1030\n",
      "           8       0.98      0.97      0.97      1007\n",
      "           9       0.95      0.96      0.96       989\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "[Linear Discriminant Analysis - raw features]\n",
      "\taccuracy score: 0.8151\n",
      "\tClassification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.79       961\n",
      "           1       0.93      1.00      0.96       936\n",
      "           2       0.68      0.70      0.69       970\n",
      "           3       0.85      0.80      0.82      1056\n",
      "           4       0.74      0.70      0.72      1060\n",
      "           5       0.89      0.89      0.89      1004\n",
      "           6       0.56      0.54      0.55      1024\n",
      "           7       0.89      0.88      0.89      1011\n",
      "           8       0.92      0.94      0.93       983\n",
      "           9       0.91      0.91      0.91       995\n",
      "\n",
      "    accuracy                           0.82     10000\n",
      "   macro avg       0.82      0.82      0.82     10000\n",
      "weighted avg       0.81      0.82      0.81     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# image classification - raw features\n",
    "train_features = raw_train_features\n",
    "train_labels = raw_train_labels\n",
    "test_features = raw_test_features\n",
    "test_labels = raw_test_labels\n",
    "\n",
    "# logistic regression - raw features\n",
    "lr = LogisticRegression()\n",
    "lr.fit(train_features, train_labels)\n",
    "lr_predict = lr.predict(test_features)\n",
    "print(\"[Logistic Regression - raw features]\\n\\taccuracy score: %.4f\" % accuracy_score(lr_predict, test_labels))\n",
    "print(\"\\tClassification report:\\n%s\\n\" % classification_report(lr_predict, test_labels))\n",
    "# Support Vector Machine - raw features\n",
    "svm = SVC()\n",
    "svm.fit(train_features, train_labels)\n",
    "svm_predict = svm.predict(test_features)\n",
    "print(\"[Support Vector Machine - raw features]\\n\\taccuracy score: %.4f\" % accuracy_score(svm_predict, test_labels))\n",
    "print(\"\\tClassification report:\\n%s\\n\" % classification_report(svm_predict, test_labels))\n",
    "# Linear Discriminant Analysis - raw features\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(train_features, train_labels)\n",
    "lda_predict = lda.predict(test_features)\n",
    "print(\"[Linear Discriminant Analysis - raw features]\\n\\taccuracy score: %.4f\" % accuracy_score(lda_predict, test_labels))\n",
    "print(\"\\tClassification report:\\n%s\\n\" % classification_report(lda_predict, test_labels))\n",
    "# Random Forest - raw features\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(train_features, train_labels)\n",
    "rfc_predict = rfc.predict(test_features)\n",
    "print(\"[Random Forest - raw features]\\n\\taccuracy score: %.4f\" % accuracy_score(rfc_predict, test_labels))\n",
    "print(\"\\tClassification report:\\n%s\\n\" % classification_report(rfc_predict, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\goodh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Logistic Regression - resnet extracted features]\n",
      "\taccuracy score: 0.9358\n",
      "\tClassification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       978\n",
      "           1       0.99      0.99      0.99       994\n",
      "           2       0.93      0.88      0.90      1049\n",
      "           3       0.93      0.93      0.93       998\n",
      "           4       0.95      0.88      0.91      1071\n",
      "           5       0.99      0.99      0.99       996\n",
      "           6       0.77      0.85      0.81       910\n",
      "           7       0.97      0.97      0.97      1007\n",
      "           8       0.99      0.99      0.99       999\n",
      "           9       0.97      0.97      0.97       998\n",
      "\n",
      "    accuracy                           0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "\n",
      "[Support Vector Machine - resnet extracted features]\n",
      "\taccuracy score: 0.9402\n",
      "\tClassification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       978\n",
      "           1       0.99      0.99      0.99       996\n",
      "           2       0.93      0.90      0.91      1034\n",
      "           3       0.94      0.94      0.94       997\n",
      "           4       0.95      0.89      0.92      1069\n",
      "           5       0.98      0.99      0.99       994\n",
      "           6       0.79      0.86      0.82       925\n",
      "           7       0.98      0.97      0.97      1010\n",
      "           8       0.99      0.99      0.99      1001\n",
      "           9       0.97      0.98      0.97       996\n",
      "\n",
      "    accuracy                           0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "\n",
      "[Linear Discriminant Analysis - resnet extracted features]\n",
      "\taccuracy score: 0.9358\n",
      "\tClassification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.89       959\n",
      "           1       0.98      1.00      0.99       983\n",
      "           2       0.93      0.90      0.91      1033\n",
      "           3       0.94      0.94      0.94      1002\n",
      "           4       0.93      0.88      0.91      1054\n",
      "           5       0.98      0.99      0.99       990\n",
      "           6       0.80      0.82      0.81       976\n",
      "           7       0.98      0.96      0.97      1026\n",
      "           8       0.99      0.99      0.99       993\n",
      "           9       0.96      0.98      0.97       984\n",
      "\n",
      "    accuracy                           0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# image classification - resnet\n",
    "# train_features = resnet_features[:60000,:]\n",
    "# train_labels = resnet_labels[:60000]\n",
    "# test_features = resnet_features[60000:,:]\n",
    "# test_labels = resnet_labels[60000:]\n",
    "train_features = resnet_train_features\n",
    "train_labels = resnet_train_labels\n",
    "test_features = resnet_test_features\n",
    "test_labels = resnet_test_labels\n",
    "\n",
    "# logistic regression - resnet extracted features\n",
    "lr = LogisticRegression()\n",
    "lr.fit(train_features, train_labels)\n",
    "lr_predict = lr.predict(test_features)\n",
    "print(\"[Logistic Regression - resnet extracted features]\\n\\taccuracy score: %.4f\" % accuracy_score(lr_predict, test_labels))\n",
    "print(\"\\tClassification report:\\n%s\\n\" % classification_report(lr_predict, test_labels))\n",
    "# Support Vector Machine - resnet extracted features\n",
    "svm = SVC()\n",
    "svm.fit(train_features, train_labels)\n",
    "svm_predict = svm.predict(test_features)\n",
    "print(\"[Support Vector Machine - resnet extracted features]\\n\\taccuracy score: %.4f\" % accuracy_score(svm_predict, test_labels))\n",
    "print(\"\\tClassification report:\\n%s\\n\" % classification_report(svm_predict, test_labels))\n",
    "# Linear Discriminant Analysis - resnet extracted features\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(train_features, train_labels)\n",
    "lda_predict = lda.predict(test_features)\n",
    "print(\"[Linear Discriminant Analysis - resnet extracted features]\\n\\taccuracy score: %.4f\" % accuracy_score(lda_predict, test_labels))\n",
    "print(\"\\tClassification report:\\n%s\\n\" % classification_report(lda_predict, test_labels))\n",
    "# Random Forest - resnet extracted features\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(train_features, train_labels)\n",
    "rfc_predict = rfc.predict(test_features)\n",
    "print(\"[Random Forest - resnet extracted features]\\n\\taccuracy score: %.4f\" % accuracy_score(rfc_predict, test_labels))\n",
    "print(\"\\tClassification report:\\n%s\\n\" % classification_report(rfc_predict, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\goodh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Logistic Regression - scattering net extracted features]\n",
      "\taccuracy score: 0.8805\n",
      "\tClassification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1002\n",
      "           1       0.97      0.98      0.97       990\n",
      "           2       0.79      0.84      0.81       946\n",
      "           3       0.89      0.85      0.87      1042\n",
      "           4       0.83      0.78      0.80      1056\n",
      "           5       0.97      0.97      0.97      1003\n",
      "           6       0.66      0.70      0.68       946\n",
      "           7       0.95      0.94      0.94      1010\n",
      "           8       0.97      0.96      0.96      1014\n",
      "           9       0.95      0.96      0.96       991\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "[Support Vector Machine - scattering net extracted features]\n",
      "\taccuracy score: 0.8869\n",
      "\tClassification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84      1042\n",
      "           1       0.97      0.99      0.98       980\n",
      "           2       0.81      0.84      0.83       969\n",
      "           3       0.90      0.86      0.88      1045\n",
      "           4       0.82      0.80      0.81      1030\n",
      "           5       0.96      0.98      0.97       982\n",
      "           6       0.64      0.70      0.67       916\n",
      "           7       0.96      0.93      0.95      1027\n",
      "           8       0.98      0.97      0.97      1013\n",
      "           9       0.96      0.96      0.96       996\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "\n",
      "[Linear Discriminant Analysis - scattering net extracted features]\n",
      "\taccuracy score: 0.9019\n",
      "\tClassification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85       996\n",
      "           1       0.96      1.00      0.98       968\n",
      "           2       0.84      0.86      0.85       984\n",
      "           3       0.91      0.88      0.90      1030\n",
      "           4       0.84      0.83      0.84      1005\n",
      "           5       0.97      0.99      0.98       984\n",
      "           6       0.72      0.70      0.71      1023\n",
      "           7       0.98      0.94      0.96      1042\n",
      "           8       0.98      0.99      0.98       990\n",
      "           9       0.96      0.98      0.97       978\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# image classification - scattering nets\n",
    "train_features = scatter_train_features\n",
    "train_labels = scatter_train_labels\n",
    "test_features = scatter_test_features\n",
    "test_labels = scatter_test_labels\n",
    "\n",
    "# logistic regression - scattering net extracted features\n",
    "lr = LogisticRegression()\n",
    "lr.fit(train_features, train_labels)\n",
    "lr_predict = lr.predict(test_features)\n",
    "print(\"[Logistic Regression - scattering net extracted features]\\n\\taccuracy score: %.4f\" % accuracy_score(lr_predict, test_labels))\n",
    "print(\"\\tClassification report:\\n%s\\n\" % classification_report(lr_predict, test_labels))\n",
    "# Support Vector Machine - scattering net extracted features\n",
    "svm = SVC()\n",
    "svm.fit(train_features, train_labels)\n",
    "svm_predict = svm.predict(test_features)\n",
    "print(\"[Support Vector Machine - scattering net extracted features]\\n\\taccuracy score: %.4f\" % accuracy_score(svm_predict, test_labels))\n",
    "print(\"\\tClassification report:\\n%s\\n\" % classification_report(svm_predict, test_labels))\n",
    "# Linear Discriminant Analysis - scattering net extracted features\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(train_features, train_labels)\n",
    "lda_predict = lda.predict(test_features)\n",
    "print(\"[Linear Discriminant Analysis - scattering net extracted features]\\n\\taccuracy score: %.4f\" % accuracy_score(lda_predict, test_labels))\n",
    "print(\"\\tClassification report:\\n%s\\n\" % classification_report(lda_predict, test_labels))\n",
    "# Random Forest - scattering net extracted features\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(train_features, train_labels)\n",
    "rfc_predict = rfc.predict(test_features)\n",
    "print(\"[Random Forest - scattering net features]\\n\\taccuracy score: %.4f\" % accuracy_score(rfc_predict, test_labels))\n",
    "print(\"\\tClassification report:\\n%s\\n\" % classification_report(rfc_predict, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
